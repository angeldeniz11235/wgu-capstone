{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load apple_df_ML.pkl\n",
    "apple_df_ML = pickle.load(open('apple_df_ML.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116.759684, 116.865102, 116.747758, ..., 116.736085, 116.768768,\n",
       "        116.790573],\n",
       "       [114.420705, 114.002524, 113.957528, ..., 114.433863, 114.488096,\n",
       "        114.661564],\n",
       "       [113.606819, 113.845019, 113.947424, ..., 115.136823, 115.125646,\n",
       "        115.174199],\n",
       "       ...,\n",
       "       [141.985858, 142.114042, 142.227377, ..., 138.915147, 138.994524,\n",
       "        138.938381],\n",
       "       [137.599456, 137.384981, 137.338305, ..., 139.948746, 139.987529,\n",
       "        139.921587],\n",
       "       [137.627544, 137.508483, 137.48028 , ..., 136.956956, 136.90308 ,\n",
       "        136.792118]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = apple_df_ML.drop('gain', axis=1).values\n",
    "y = apple_df_ML['gain'].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TF_ENABLE_ONEDNN_OPTS=0\n",
    "!CUDA_VISIBLE_DEVICES=0\n",
    "!TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(Dense(units=1000, activation=activations.softplus , input_shape=(X_train.shape[1],)))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(units=500, activation=activations.softplus))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(units=250, activation=activations.softplus))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units=1000, activation=activations.softmax))\n",
    "model.add(Dropout(0.01))\n",
    "\n",
    "#model.add(Dense(units=50, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=750, activation=activations.gelu))\n",
    "model.add(Dropout(0.02))\n",
    "\n",
    "#model.add(Dense(units=10, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(units=4, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units=1, activation=activations.sigmoid))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#binary_crossentropy\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.6934 - val_loss: 0.6933\n",
      "Epoch 2/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6932 - val_loss: 0.6916\n",
      "Epoch 3/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6929 - val_loss: 0.6906\n",
      "Epoch 4/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6929 - val_loss: 0.6897\n",
      "Epoch 5/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6929 - val_loss: 0.6891\n",
      "Epoch 6/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6931 - val_loss: 0.6887\n",
      "Epoch 7/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6933 - val_loss: 0.6887\n",
      "Epoch 8/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6931 - val_loss: 0.6892\n",
      "Epoch 9/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6930 - val_loss: 0.6899\n",
      "Epoch 10/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6930 - val_loss: 0.6907\n",
      "Epoch 11/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6929 - val_loss: 0.6913\n",
      "Epoch 12/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6929 - val_loss: 0.6917\n",
      "Epoch 13/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6929 - val_loss: 0.6922\n",
      "Epoch 14/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6930 - val_loss: 0.6924\n",
      "Epoch 15/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6930 - val_loss: 0.6924\n",
      "Epoch 16/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6929 - val_loss: 0.6925\n",
      "Epoch 17/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6929 - val_loss: 0.6926\n",
      "Epoch 18/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6929 - val_loss: 0.6924\n",
      "Epoch 19/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6929 - val_loss: 0.6921\n",
      "Epoch 20/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6928 - val_loss: 0.6917\n",
      "Epoch 21/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6929 - val_loss: 0.6913\n",
      "Epoch 22/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6928 - val_loss: 0.6911\n",
      "Epoch 23/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6927 - val_loss: 0.6912\n",
      "Epoch 24/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6927 - val_loss: 0.6911\n",
      "Epoch 25/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6929 - val_loss: 0.6913\n",
      "Epoch 26/350\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6927 - val_loss: 0.6909\n",
      "Epoch 27/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6929 - val_loss: 0.6906\n",
      "Epoch 28/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6927 - val_loss: 0.6908\n",
      "Epoch 29/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6928 - val_loss: 0.6909\n",
      "Epoch 30/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6927 - val_loss: 0.6905\n",
      "Epoch 31/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6926 - val_loss: 0.6902\n",
      "Epoch 32/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6927 - val_loss: 0.6899\n",
      "Epoch 33/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6927 - val_loss: 0.6897\n",
      "Epoch 34/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6927 - val_loss: 0.6894\n",
      "Epoch 35/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6928 - val_loss: 0.6893\n",
      "Epoch 36/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6927 - val_loss: 0.6898\n",
      "Epoch 37/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6926 - val_loss: 0.6906\n",
      "Epoch 38/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6924 - val_loss: 0.6914\n",
      "Epoch 39/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6924 - val_loss: 0.6925\n",
      "Epoch 40/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6924 - val_loss: 0.6936\n",
      "Epoch 41/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6926 - val_loss: 0.6944\n",
      "Epoch 42/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6926 - val_loss: 0.6940\n",
      "Epoch 43/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 44/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6920 - val_loss: 0.6905\n",
      "Epoch 45/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6920 - val_loss: 0.6892\n",
      "Epoch 46/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6922 - val_loss: 0.6884\n",
      "Epoch 47/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6924 - val_loss: 0.6880\n",
      "Epoch 48/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6926 - val_loss: 0.6877\n",
      "Epoch 49/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6926 - val_loss: 0.6887\n",
      "Epoch 50/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6921 - val_loss: 0.6915\n",
      "Epoch 51/350\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6912 - val_loss: 0.6942\n",
      "Epoch 52/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6915 - val_loss: 0.6969\n",
      "Epoch 53/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6922 - val_loss: 0.6978\n",
      "Epoch 54/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6918 - val_loss: 0.6954\n",
      "Epoch 55/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6911 - val_loss: 0.6931\n",
      "Epoch 56/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6906 - val_loss: 0.6902\n",
      "Epoch 57/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6907 - val_loss: 0.6880\n",
      "Epoch 58/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6917 - val_loss: 0.6880\n",
      "Epoch 59/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6910 - val_loss: 0.6913\n",
      "Epoch 60/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6896 - val_loss: 0.6954\n",
      "Epoch 61/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6911 - val_loss: 0.6984\n",
      "Epoch 62/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6906 - val_loss: 0.6951\n",
      "Epoch 63/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6890 - val_loss: 0.6912\n",
      "Epoch 64/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6890 - val_loss: 0.6882\n",
      "Epoch 65/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6905 - val_loss: 0.6890\n",
      "Epoch 66/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6894 - val_loss: 0.6941\n",
      "Epoch 67/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6889 - val_loss: 0.6962\n",
      "Epoch 68/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6879 - val_loss: 0.6925\n",
      "Epoch 69/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6874 - val_loss: 0.6878\n",
      "Epoch 70/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6875 - val_loss: 0.6874\n",
      "Epoch 71/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6880 - val_loss: 0.6901\n",
      "Epoch 72/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6862 - val_loss: 0.6911\n",
      "Epoch 73/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6854 - val_loss: 0.6889\n",
      "Epoch 74/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6845 - val_loss: 0.6862\n",
      "Epoch 75/350\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6843 - val_loss: 0.6874\n",
      "Epoch 76/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6824 - val_loss: 0.6964\n",
      "Epoch 77/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6821 - val_loss: 0.7019\n",
      "Epoch 78/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6812 - val_loss: 0.6908\n",
      "Epoch 79/350\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6794 - val_loss: 0.6823\n",
      "Epoch 80/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6799 - val_loss: 0.6876\n",
      "Epoch 81/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6793 - val_loss: 0.7001\n",
      "Epoch 82/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6769 - val_loss: 0.6838\n",
      "Epoch 83/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6759 - val_loss: 0.6809\n",
      "Epoch 84/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6718 - val_loss: 0.6978\n",
      "Epoch 85/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6728 - val_loss: 0.6924\n",
      "Epoch 86/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6681 - val_loss: 0.6784\n",
      "Epoch 87/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6732 - val_loss: 0.6838\n",
      "Epoch 88/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6677 - val_loss: 0.7156\n",
      "Epoch 89/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6746 - val_loss: 0.6791\n",
      "Epoch 90/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6638 - val_loss: 0.6707\n",
      "Epoch 91/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6678 - val_loss: 0.6775\n",
      "Epoch 92/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6561 - val_loss: 0.6729\n",
      "Epoch 93/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6601 - val_loss: 0.6710\n",
      "Epoch 94/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6543 - val_loss: 0.6696\n",
      "Epoch 95/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6559 - val_loss: 0.6761\n",
      "Epoch 96/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6528 - val_loss: 0.6795\n",
      "Epoch 97/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6472 - val_loss: 0.6675\n",
      "Epoch 98/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6467 - val_loss: 0.6684\n",
      "Epoch 99/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6419 - val_loss: 0.6597\n",
      "Epoch 100/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6392 - val_loss: 0.6574\n",
      "Epoch 101/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6349 - val_loss: 0.6731\n",
      "Epoch 102/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6326 - val_loss: 0.6666\n",
      "Epoch 103/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6278 - val_loss: 0.6576\n",
      "Epoch 104/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6227 - val_loss: 0.6555\n",
      "Epoch 105/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6171 - val_loss: 0.6521\n",
      "Epoch 106/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6168 - val_loss: 0.6571\n",
      "Epoch 107/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6133 - val_loss: 0.6451\n",
      "Epoch 108/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6062 - val_loss: 0.6426\n",
      "Epoch 109/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6067 - val_loss: 0.6747\n",
      "Epoch 110/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6123 - val_loss: 0.6353\n",
      "Epoch 111/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5973 - val_loss: 0.6596\n",
      "Epoch 112/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6018 - val_loss: 0.6343\n",
      "Epoch 113/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5908 - val_loss: 0.6411\n",
      "Epoch 114/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5864 - val_loss: 0.6288\n",
      "Epoch 115/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5878 - val_loss: 0.6466\n",
      "Epoch 116/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5910 - val_loss: 0.6271\n",
      "Epoch 117/350\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5871 - val_loss: 0.6282\n",
      "Epoch 118/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5789 - val_loss: 0.6297\n",
      "Epoch 119/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5911 - val_loss: 0.6457\n",
      "Epoch 120/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5872 - val_loss: 0.6111\n",
      "Epoch 121/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5828 - val_loss: 0.6083\n",
      "Epoch 122/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5899 - val_loss: 0.6120\n",
      "Epoch 123/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5743 - val_loss: 0.6209\n",
      "Epoch 124/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5962 - val_loss: 0.6199\n",
      "Epoch 125/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5595 - val_loss: 0.6241\n",
      "Epoch 126/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5888 - val_loss: 0.6038\n",
      "Epoch 127/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5629 - val_loss: 0.6289\n",
      "Epoch 128/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5711 - val_loss: 0.6111\n",
      "Epoch 129/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5684 - val_loss: 0.6055\n",
      "Epoch 130/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5685 - val_loss: 0.6017\n",
      "Epoch 131/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5533 - val_loss: 0.6111\n",
      "Epoch 132/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5632 - val_loss: 0.6166\n",
      "Epoch 133/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5637 - val_loss: 0.5981\n",
      "Epoch 134/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5540 - val_loss: 0.6018\n",
      "Epoch 135/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5550 - val_loss: 0.6172\n",
      "Epoch 136/350\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5580 - val_loss: 0.5985\n",
      "Epoch 137/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5539 - val_loss: 0.5917\n",
      "Epoch 138/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5685 - val_loss: 0.5913\n",
      "Epoch 139/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5413 - val_loss: 0.6243\n",
      "Epoch 140/350\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5718 - val_loss: 0.6014\n",
      "Epoch 141/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5484 - val_loss: 0.5984\n",
      "Epoch 142/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5419 - val_loss: 0.5967\n",
      "Epoch 143/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5498 - val_loss: 0.6011\n",
      "Epoch 144/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5445 - val_loss: 0.6093\n",
      "Epoch 145/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5478 - val_loss: 0.6064\n",
      "Epoch 146/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5544 - val_loss: 0.5945\n",
      "Epoch 147/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5434 - val_loss: 0.5985\n",
      "Epoch 148/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5399 - val_loss: 0.5965\n",
      "Epoch 149/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5390 - val_loss: 0.6002\n",
      "Epoch 150/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5412 - val_loss: 0.5863\n",
      "Epoch 151/350\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5397 - val_loss: 0.5844\n",
      "Epoch 152/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5425 - val_loss: 0.5837\n",
      "Epoch 153/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5399 - val_loss: 0.5823\n",
      "Epoch 154/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5386 - val_loss: 0.5918\n",
      "Epoch 155/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5427 - val_loss: 0.5815\n",
      "Epoch 156/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5346 - val_loss: 0.5926\n",
      "Epoch 157/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5409 - val_loss: 0.5783\n",
      "Epoch 158/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5300 - val_loss: 0.5806\n",
      "Epoch 159/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5312 - val_loss: 0.5844\n",
      "Epoch 160/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5318 - val_loss: 0.5789\n",
      "Epoch 161/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5348 - val_loss: 0.5807\n",
      "Epoch 162/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5280 - val_loss: 0.5767\n",
      "Epoch 163/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5304 - val_loss: 0.5776\n",
      "Epoch 164/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5328 - val_loss: 0.5775\n",
      "Epoch 165/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5304 - val_loss: 0.5790\n",
      "Epoch 166/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5227 - val_loss: 0.5899\n",
      "Epoch 167/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5373 - val_loss: 0.5984\n",
      "Epoch 168/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5338 - val_loss: 0.5795\n",
      "Epoch 169/350\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5296 - val_loss: 0.5811\n",
      "Epoch 170/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5308 - val_loss: 0.5798\n",
      "Epoch 171/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5266 - val_loss: 0.5769\n",
      "Epoch 172/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5182 - val_loss: 0.5764\n",
      "Epoch 173/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5214 - val_loss: 0.5766\n",
      "Epoch 174/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5222 - val_loss: 0.5735\n",
      "Epoch 175/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5225 - val_loss: 0.5740\n",
      "Epoch 176/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5253 - val_loss: 0.5707\n",
      "Epoch 177/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5195 - val_loss: 0.5798\n",
      "Epoch 178/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5264 - val_loss: 0.5808\n",
      "Epoch 179/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5380 - val_loss: 0.5721\n",
      "Epoch 180/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5223 - val_loss: 0.5761\n",
      "Epoch 181/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5237 - val_loss: 0.5796\n",
      "Epoch 182/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5239 - val_loss: 0.5751\n",
      "Epoch 183/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5260 - val_loss: 0.5713\n",
      "Epoch 184/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5222 - val_loss: 0.5745\n",
      "Epoch 185/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5341 - val_loss: 0.5943\n",
      "Epoch 186/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5350 - val_loss: 0.5812\n",
      "Epoch 187/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5248 - val_loss: 0.5731\n",
      "Epoch 188/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5324 - val_loss: 0.5766\n",
      "Epoch 189/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5245 - val_loss: 0.5865\n",
      "Epoch 190/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5251 - val_loss: 0.5771\n",
      "Epoch 191/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5322 - val_loss: 0.5720\n",
      "Epoch 192/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5172 - val_loss: 0.5712\n",
      "Epoch 193/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5240 - val_loss: 0.5698\n",
      "Epoch 194/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5219 - val_loss: 0.5672\n",
      "Epoch 195/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5320 - val_loss: 0.5992\n",
      "Epoch 196/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5475 - val_loss: 0.5709\n",
      "Epoch 197/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5204 - val_loss: 0.5910\n",
      "Epoch 198/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5358 - val_loss: 0.5951\n",
      "Epoch 199/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5288 - val_loss: 0.5788\n",
      "Epoch 200/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5243 - val_loss: 0.5703\n",
      "Epoch 201/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5291 - val_loss: 0.5695\n",
      "Epoch 202/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5206 - val_loss: 0.5795\n",
      "Epoch 203/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5230 - val_loss: 0.5854\n",
      "Epoch 204/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5268 - val_loss: 0.5720\n",
      "Epoch 205/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5229 - val_loss: 0.5689\n",
      "Epoch 206/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5192 - val_loss: 0.5749\n",
      "Epoch 207/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5320 - val_loss: 0.5702\n",
      "Epoch 208/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5194 - val_loss: 0.5845\n",
      "Epoch 209/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5240 - val_loss: 0.5731\n",
      "Epoch 210/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5208 - val_loss: 0.5697\n",
      "Epoch 211/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5131 - val_loss: 0.5713\n",
      "Epoch 212/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5170 - val_loss: 0.5716\n",
      "Epoch 213/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5174 - val_loss: 0.5728\n",
      "Epoch 214/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5192 - val_loss: 0.5708\n",
      "Epoch 215/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5212 - val_loss: 0.5693\n",
      "Epoch 216/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5301 - val_loss: 0.5683\n",
      "Epoch 217/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5250 - val_loss: 0.5722\n",
      "Epoch 218/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5166 - val_loss: 0.5947\n",
      "Epoch 219/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5261 - val_loss: 0.5729\n",
      "Epoch 220/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5269 - val_loss: 0.5667\n",
      "Epoch 221/350\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5250 - val_loss: 0.5662\n",
      "Epoch 222/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5173 - val_loss: 0.5718\n",
      "Epoch 223/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5187 - val_loss: 0.5940\n",
      "Epoch 224/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5286 - val_loss: 0.5700\n",
      "Epoch 225/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5296 - val_loss: 0.5672\n",
      "Epoch 226/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5177 - val_loss: 0.5823\n",
      "Epoch 227/350\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5237 - val_loss: 0.5723\n",
      "Epoch 228/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5217 - val_loss: 0.5731\n",
      "Epoch 229/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5256 - val_loss: 0.5647\n",
      "Epoch 230/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5269 - val_loss: 0.5646\n",
      "Epoch 231/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5238 - val_loss: 0.5704\n",
      "Epoch 232/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5134 - val_loss: 0.5754\n",
      "Epoch 233/350\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5245 - val_loss: 0.5734\n",
      "Epoch 234/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5169 - val_loss: 0.5674\n",
      "Epoch 235/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5157 - val_loss: 0.5733\n",
      "Epoch 236/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5170 - val_loss: 0.5809\n",
      "Epoch 237/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5235 - val_loss: 0.5672\n",
      "Epoch 238/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5185 - val_loss: 0.5661\n",
      "Epoch 239/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5224 - val_loss: 0.5654\n",
      "Epoch 240/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5149 - val_loss: 0.5689\n",
      "Epoch 241/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5296 - val_loss: 0.5685\n",
      "Epoch 242/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5102 - val_loss: 0.5784\n",
      "Epoch 243/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5264 - val_loss: 0.5775\n",
      "Epoch 244/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5240 - val_loss: 0.5721\n",
      "Epoch 245/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5157 - val_loss: 0.5885\n",
      "Epoch 246/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5255 - val_loss: 0.5852\n",
      "Epoch 247/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5209 - val_loss: 0.5677\n",
      "Epoch 248/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5128 - val_loss: 0.5794\n",
      "Epoch 249/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5251 - val_loss: 0.5720\n",
      "Epoch 250/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5163 - val_loss: 0.5677\n",
      "Epoch 251/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5178 - val_loss: 0.5682\n",
      "Epoch 252/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5143 - val_loss: 0.5684\n",
      "Epoch 253/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5152 - val_loss: 0.5675\n",
      "Epoch 254/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5139 - val_loss: 0.5768\n",
      "Epoch 255/350\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5152 - val_loss: 0.5727\n",
      "Epoch 256/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5258 - val_loss: 0.5663\n",
      "Epoch 257/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5279 - val_loss: 0.5714\n",
      "Epoch 258/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5272 - val_loss: 0.5735\n",
      "Epoch 259/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5161 - val_loss: 0.5804\n",
      "Epoch 260/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5214 - val_loss: 0.5632\n",
      "Epoch 261/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5109 - val_loss: 0.5725\n",
      "Epoch 262/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5199 - val_loss: 0.5743\n",
      "Epoch 263/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5207 - val_loss: 0.5712\n",
      "Epoch 264/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5091 - val_loss: 0.5717\n",
      "Epoch 265/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5179 - val_loss: 0.5684\n",
      "Epoch 266/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5134 - val_loss: 0.5659\n",
      "Epoch 267/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5143 - val_loss: 0.5730\n",
      "Epoch 268/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5195 - val_loss: 0.5771\n",
      "Epoch 269/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5196 - val_loss: 0.5883\n",
      "Epoch 270/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5226 - val_loss: 0.5834\n",
      "Epoch 271/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5288 - val_loss: 0.5698\n",
      "Epoch 272/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5114 - val_loss: 0.5914\n",
      "Epoch 273/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5195 - val_loss: 0.5825\n",
      "Epoch 274/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5402 - val_loss: 0.5714\n",
      "Epoch 275/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5126 - val_loss: 0.6150\n",
      "Epoch 276/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5375 - val_loss: 0.5793\n",
      "Epoch 277/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5253 - val_loss: 0.5661\n",
      "Epoch 278/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5152 - val_loss: 0.5709\n",
      "Epoch 279/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5084 - val_loss: 0.5693\n",
      "Epoch 280/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5162 - val_loss: 0.5645\n",
      "Epoch 281/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5103 - val_loss: 0.5661\n",
      "Epoch 282/350\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5116 - val_loss: 0.5632\n",
      "Epoch 283/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5108 - val_loss: 0.5676\n",
      "Epoch 284/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5125 - val_loss: 0.5683\n",
      "Epoch 285/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5257 - val_loss: 0.5646\n",
      "Epoch 286/350\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5109 - val_loss: 0.5775\n",
      "Epoch 287/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5121 - val_loss: 0.5934\n",
      "Epoch 288/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5344 - val_loss: 0.5673\n",
      "Epoch 289/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5091 - val_loss: 0.5699\n",
      "Epoch 290/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5093 - val_loss: 0.5656\n",
      "Epoch 291/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5120 - val_loss: 0.5655\n",
      "Epoch 292/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5056 - val_loss: 0.5732\n",
      "Epoch 293/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5196 - val_loss: 0.5653\n",
      "Epoch 294/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5133 - val_loss: 0.5704\n",
      "Epoch 295/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5119 - val_loss: 0.5646\n",
      "Epoch 296/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5081 - val_loss: 0.5648\n",
      "Epoch 297/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5060 - val_loss: 0.5662\n",
      "Epoch 298/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5084 - val_loss: 0.5665\n",
      "Epoch 299/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5071 - val_loss: 0.5703\n",
      "Epoch 300/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5059 - val_loss: 0.5746\n",
      "Epoch 301/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5130 - val_loss: 0.5715\n",
      "Epoch 302/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5145 - val_loss: 0.5690\n",
      "Epoch 303/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5088 - val_loss: 0.5953\n",
      "Epoch 304/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5243 - val_loss: 0.5701\n",
      "Epoch 305/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5210 - val_loss: 0.5783\n",
      "Epoch 306/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5266 - val_loss: 0.5775\n",
      "Epoch 307/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5143 - val_loss: 0.5655\n",
      "Epoch 308/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5059 - val_loss: 0.5722\n",
      "Epoch 309/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5152 - val_loss: 0.5684\n",
      "Epoch 310/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5106 - val_loss: 0.5632\n",
      "Epoch 311/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5034 - val_loss: 0.5652\n",
      "Epoch 312/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5043 - val_loss: 0.5643\n",
      "Epoch 313/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5116 - val_loss: 0.5657\n",
      "Epoch 314/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5050 - val_loss: 0.5696\n",
      "Epoch 315/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5060 - val_loss: 0.5700\n",
      "Epoch 316/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5073 - val_loss: 0.5808\n",
      "Epoch 317/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5219 - val_loss: 0.5745\n",
      "Epoch 318/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5124 - val_loss: 0.5700\n",
      "Epoch 319/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5051 - val_loss: 0.5794\n",
      "Epoch 320/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5143 - val_loss: 0.5691\n",
      "Epoch 321/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5057 - val_loss: 0.5767\n",
      "Epoch 322/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5134 - val_loss: 0.5775\n",
      "Epoch 323/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5163 - val_loss: 0.5688\n",
      "Epoch 324/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5122 - val_loss: 0.5700\n",
      "Epoch 325/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5093 - val_loss: 0.5733\n",
      "Epoch 326/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5147 - val_loss: 0.5654\n",
      "Epoch 327/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5141 - val_loss: 0.5655\n",
      "Epoch 328/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5054 - val_loss: 0.5792\n",
      "Epoch 329/350\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5218 - val_loss: 0.5652\n",
      "Epoch 330/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5269 - val_loss: 0.5652\n",
      "Epoch 331/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5127 - val_loss: 0.5907\n",
      "Epoch 332/350\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5302 - val_loss: 0.5646\n",
      "Epoch 333/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5044 - val_loss: 0.5654\n",
      "Epoch 334/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5101 - val_loss: 0.5670\n",
      "Epoch 335/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5118 - val_loss: 0.5665\n",
      "Epoch 336/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5103 - val_loss: 0.5717\n",
      "Epoch 337/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5111 - val_loss: 0.5709\n",
      "Epoch 338/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5077 - val_loss: 0.5670\n",
      "Epoch 339/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5043 - val_loss: 0.5753\n",
      "Epoch 340/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5056 - val_loss: 0.5712\n",
      "Epoch 341/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5135 - val_loss: 0.5771\n",
      "Epoch 342/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5068 - val_loss: 0.5735\n",
      "Epoch 343/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5153 - val_loss: 0.5747\n",
      "Epoch 344/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5235 - val_loss: 0.5733\n",
      "Epoch 345/350\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5042 - val_loss: 0.5938\n",
      "Epoch 346/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5312 - val_loss: 0.5658\n",
      "Epoch 347/350\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5069 - val_loss: 0.5936\n",
      "Epoch 348/350\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5209 - val_loss: 0.5750\n",
      "Epoch 349/350\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5288 - val_loss: 0.5685\n",
      "Epoch 350/350\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5232 - val_loss: 0.5861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4712dc76d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(x=X_train, y=y_train, epochs=350, batch_size=256, validation_data=(X_test, y_test), verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if model.predict(X_test) > 0.44 then 1 else 0:\n",
    "predictions = model.predict(X_test)\n",
    "offset = .00\n",
    "predictions[predictions > (predictions.mean() + offset)] = 1\n",
    "predictions[predictions <= (predictions.mean() + offset)] = 0\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63        42\n",
      "           1       0.71      0.74      0.73        54\n",
      "\n",
      "    accuracy                           0.69        96\n",
      "   macro avg       0.68      0.68      0.68        96\n",
      "weighted avg       0.69      0.69      0.69        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26, 16],\n",
       "       [14, 40]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('wgu-capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28892a974b391ec4cda080504c9714056d5a77d99c120a0e73eaf6e1e5cc7d13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
